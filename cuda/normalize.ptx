//
// Generated by NVIDIA NVVM Compiler
//
// Compiler Build ID: CL-21124049
// Cuda compilation tools, release 8.0, V8.0.44
// Based on LLVM 3.4svn
//

.version 5.0
.target sm_20
.address_size 64

	// .globl	normalize

.visible .entry normalize(
	.param .u64 normalize_param_0,
	.param .u64 normalize_param_1,
	.param .u32 normalize_param_2,
	.param .u32 normalize_param_3
)
{
	.reg .pred 	%p<5>;
	.reg .f32 	%f<3>;
	.reg .b32 	%r<22>;
	.reg .f64 	%fd<43>;
	.reg .b64 	%rd<12>;


	ld.param.u64 	%rd2, [normalize_param_0];
	ld.param.u64 	%rd3, [normalize_param_1];
	ld.param.u32 	%r6, [normalize_param_2];
	ld.param.u32 	%r5, [normalize_param_3];
	mov.u32 	%r7, %ntid.x;
	mov.u32 	%r8, %ctaid.x;
	mov.u32 	%r9, %tid.x;
	mad.lo.s32 	%r1, %r7, %r8, %r9;
	setp.ge.u32	%p1, %r1, %r6;
	@%p1 bra 	BB0_5;

	cvta.to.global.u64 	%rd4, %rd2;
	mul.wide.s32 	%rd5, %r5, 8;
	add.s64 	%rd6, %rd4, %rd5;
	cvt.s64.s32	%rd1, %r1;
	mul.wide.s32 	%rd7, %r1, 8;
	add.s64 	%rd8, %rd4, %rd7;
	ld.global.f64 	%fd6, [%rd8];
	ldu.global.f64 	%fd7, [%rd6];
	sub.f64 	%fd1, %fd6, %fd7;
	mov.f64 	%fd8, 0d4338000000000000;
	mov.f64 	%fd9, 0d3FF71547652B82FE;
	fma.rn.f64 	%fd10, %fd1, %fd9, %fd8;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r2, %temp}, %fd10;
	}
	mov.f64 	%fd11, 0dC338000000000000;
	add.rn.f64 	%fd12, %fd10, %fd11;
	mov.f64 	%fd13, 0dBFE62E42FEFA39EF;
	fma.rn.f64 	%fd14, %fd12, %fd13, %fd1;
	mov.f64 	%fd15, 0dBC7ABC9E3B39803F;
	fma.rn.f64 	%fd16, %fd12, %fd15, %fd14;
	mov.f64 	%fd17, 0d3E928AF3FCA213EA;
	mov.f64 	%fd18, 0d3E5ADE1569CE2BDF;
	fma.rn.f64 	%fd19, %fd18, %fd16, %fd17;
	mov.f64 	%fd20, 0d3EC71DEE62401315;
	fma.rn.f64 	%fd21, %fd19, %fd16, %fd20;
	mov.f64 	%fd22, 0d3EFA01997C89EB71;
	fma.rn.f64 	%fd23, %fd21, %fd16, %fd22;
	mov.f64 	%fd24, 0d3F2A01A014761F65;
	fma.rn.f64 	%fd25, %fd23, %fd16, %fd24;
	mov.f64 	%fd26, 0d3F56C16C1852B7AF;
	fma.rn.f64 	%fd27, %fd25, %fd16, %fd26;
	mov.f64 	%fd28, 0d3F81111111122322;
	fma.rn.f64 	%fd29, %fd27, %fd16, %fd28;
	mov.f64 	%fd30, 0d3FA55555555502A1;
	fma.rn.f64 	%fd31, %fd29, %fd16, %fd30;
	mov.f64 	%fd32, 0d3FC5555555555511;
	fma.rn.f64 	%fd33, %fd31, %fd16, %fd32;
	mov.f64 	%fd34, 0d3FE000000000000B;
	fma.rn.f64 	%fd35, %fd33, %fd16, %fd34;
	mov.f64 	%fd36, 0d3FF0000000000000;
	fma.rn.f64 	%fd37, %fd35, %fd16, %fd36;
	fma.rn.f64 	%fd38, %fd37, %fd16, %fd36;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r3, %temp}, %fd38;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4}, %fd38;
	}
	shl.b32 	%r10, %r2, 20;
	add.s32 	%r11, %r4, %r10;
	mov.b64 	%fd42, {%r3, %r11};
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r12}, %fd1;
	}
	mov.b32 	 %f2, %r12;
	abs.f32 	%f1, %f2;
	setp.lt.f32	%p2, %f1, 0f4086232B;
	@%p2 bra 	BB0_4;

	setp.lt.f64	%p3, %fd1, 0d0000000000000000;
	add.f64 	%fd39, %fd1, 0d7FF0000000000000;
	selp.f64	%fd42, 0d0000000000000000, %fd39, %p3;
	setp.geu.f32	%p4, %f1, 0f40874800;
	@%p4 bra 	BB0_4;

	shr.u32 	%r13, %r2, 31;
	add.s32 	%r14, %r2, %r13;
	shr.s32 	%r15, %r14, 1;
	shl.b32 	%r16, %r15, 20;
	add.s32 	%r17, %r16, %r4;
	mov.b64 	%fd40, {%r3, %r17};
	sub.s32 	%r18, %r2, %r15;
	shl.b32 	%r19, %r18, 20;
	add.s32 	%r20, %r19, 1072693248;
	mov.u32 	%r21, 0;
	mov.b64 	%fd41, {%r21, %r20};
	mul.f64 	%fd42, %fd40, %fd41;

BB0_4:
	cvta.to.global.u64 	%rd9, %rd3;
	shl.b64 	%rd10, %rd1, 3;
	add.s64 	%rd11, %rd9, %rd10;
	st.global.f64 	[%rd11], %fd42;

BB0_5:
	ret;
}

	// .globl	getTargetIndex
.visible .entry getTargetIndex(
	.param .u32 getTargetIndex_param_0,
	.param .u64 getTargetIndex_param_1,
	.param .u64 getTargetIndex_param_2
)
{
	.reg .pred 	%p<3>;
	.reg .b32 	%r<6>;
	.reg .f64 	%fd<2>;
	.reg .b64 	%rd<7>;


	ld.param.u32 	%r2, [getTargetIndex_param_0];
	ld.param.u64 	%rd1, [getTargetIndex_param_1];
	ld.param.u64 	%rd2, [getTargetIndex_param_2];
	mov.u32 	%r3, %ntid.x;
	mov.u32 	%r4, %ctaid.x;
	mov.u32 	%r5, %tid.x;
	mad.lo.s32 	%r1, %r3, %r4, %r5;
	setp.ge.s32	%p1, %r1, %r2;
	@%p1 bra 	BB1_3;

	cvta.to.global.u64 	%rd3, %rd2;
	mul.wide.s32 	%rd4, %r1, 8;
	add.s64 	%rd5, %rd3, %rd4;
	ld.global.f64 	%fd1, [%rd5];
	setp.neu.f64	%p2, %fd1, 0d3FF0000000000000;
	@%p2 bra 	BB1_3;

	cvta.to.global.u64 	%rd6, %rd1;
	st.global.u32 	[%rd6], %r1;

BB1_3:
	ret;
}

	// .globl	mismatch
.visible .entry mismatch(
	.param .u32 mismatch_param_0,
	.param .u64 mismatch_param_1,
	.param .u64 mismatch_param_2,
	.param .u64 mismatch_param_3
)
{
	.reg .pred 	%p<6>;
	.reg .b32 	%r<9>;
	.reg .f64 	%fd<7>;
	.reg .b64 	%rd<10>;


	ld.param.u32 	%r2, [mismatch_param_0];
	ld.param.u64 	%rd4, [mismatch_param_1];
	ld.param.u64 	%rd5, [mismatch_param_2];
	ld.param.u64 	%rd6, [mismatch_param_3];
	cvta.to.global.u64 	%rd1, %rd6;
	mov.u32 	%r3, 0;
	st.global.u32 	[%rd1], %r3;
	mov.u32 	%r4, %ntid.x;
	mov.u32 	%r5, %ctaid.x;
	mov.u32 	%r6, %tid.x;
	mad.lo.s32 	%r1, %r4, %r5, %r6;
	setp.ge.s32	%p1, %r1, %r2;
	@%p1 bra 	BB2_7;

	cvta.to.global.u64 	%rd7, %rd4;
	cvta.to.global.u64 	%rd8, %rd5;
	mul.wide.s32 	%rd9, %r1, 8;
	add.s64 	%rd2, %rd8, %rd9;
	ld.global.f64 	%fd6, [%rd2];
	setp.ltu.f64	%p2, %fd6, 0d3FE0000000000000;
	add.s64 	%rd3, %rd7, %rd9;
	@%p2 bra 	BB2_4;

	ld.global.f64 	%fd4, [%rd3];
	setp.geu.f64	%p3, %fd4, 0d3FE0000000000000;
	@%p3 bra 	BB2_4;

	mov.u32 	%r7, 1;
	st.global.u32 	[%rd1], %r7;
	ld.global.f64 	%fd6, [%rd2];

BB2_4:
	setp.geu.f64	%p4, %fd6, 0d3FE0000000000000;
	@%p4 bra 	BB2_7;

	ld.global.f64 	%fd5, [%rd3];
	setp.ltu.f64	%p5, %fd5, 0d3FE0000000000000;
	@%p5 bra 	BB2_7;

	mov.u32 	%r8, 1;
	st.global.u32 	[%rd1], %r8;

BB2_7:
	ret;
}

	// .globl	setTargetIndex
.visible .entry setTargetIndex(
	.param .u32 setTargetIndex_param_0,
	.param .u64 setTargetIndex_param_1,
	.param .u64 setTargetIndex_param_2
)
{
	.reg .pred 	%p<3>;
	.reg .b32 	%r<6>;
	.reg .f64 	%fd<4>;
	.reg .b64 	%rd<10>;


	ld.param.u32 	%r2, [setTargetIndex_param_0];
	ld.param.u64 	%rd2, [setTargetIndex_param_1];
	ld.param.u64 	%rd3, [setTargetIndex_param_2];
	mov.u32 	%r3, %ntid.x;
	mov.u32 	%r4, %ctaid.x;
	mov.u32 	%r5, %tid.x;
	mad.lo.s32 	%r1, %r3, %r4, %r5;
	setp.ge.s32	%p1, %r1, %r2;
	@%p1 bra 	BB3_3;

	cvta.to.global.u64 	%rd4, %rd2;
	cvt.s64.s32	%rd1, %r1;
	mul.wide.s32 	%rd5, %r1, 8;
	add.s64 	%rd6, %rd4, %rd5;
	ld.global.f64 	%fd1, [%rd6];
	setp.neu.f64	%p2, %fd1, 0d3FF0000000000000;
	@%p2 bra 	BB3_3;

	cvta.to.global.u64 	%rd7, %rd3;
	shl.b64 	%rd8, %rd1, 3;
	add.s64 	%rd9, %rd7, %rd8;
	ld.global.f64 	%fd2, [%rd9];
	add.f64 	%fd3, %fd2, 0dBFF0000000000000;
	st.global.f64 	[%rd9], %fd3;

BB3_3:
	ret;
}

	// .globl	setTargetIndexNormalize
.visible .entry setTargetIndexNormalize(
	.param .u32 setTargetIndexNormalize_param_0,
	.param .f64 setTargetIndexNormalize_param_1,
	.param .u64 setTargetIndexNormalize_param_2,
	.param .u64 setTargetIndexNormalize_param_3,
	.param .u64 setTargetIndexNormalize_param_4
)
{
	.reg .pred 	%p<3>;
	.reg .b32 	%r<6>;
	.reg .f64 	%fd<5>;
	.reg .b64 	%rd<12>;


	ld.param.u32 	%r2, [setTargetIndexNormalize_param_0];
	ld.param.f64 	%fd1, [setTargetIndexNormalize_param_1];
	ld.param.u64 	%rd2, [setTargetIndexNormalize_param_2];
	ld.param.u64 	%rd3, [setTargetIndexNormalize_param_3];
	ld.param.u64 	%rd4, [setTargetIndexNormalize_param_4];
	mov.u32 	%r3, %ntid.x;
	mov.u32 	%r4, %ctaid.x;
	mov.u32 	%r5, %tid.x;
	mad.lo.s32 	%r1, %r3, %r4, %r5;
	setp.ge.s32	%p1, %r1, %r2;
	@%p1 bra 	BB4_3;

	cvta.to.global.u64 	%rd5, %rd2;
	cvt.s64.s32	%rd1, %r1;
	mul.wide.s32 	%rd6, %r1, 8;
	add.s64 	%rd7, %rd5, %rd6;
	ld.global.f64 	%fd2, [%rd7];
	setp.neu.f64	%p2, %fd2, 0d3FF0000000000000;
	@%p2 bra 	BB4_3;

	cvta.to.global.u64 	%rd8, %rd4;
	cvta.to.global.u64 	%rd9, %rd3;
	shl.b64 	%rd10, %rd1, 3;
	add.s64 	%rd11, %rd9, %rd10;
	ld.global.f64 	%fd3, [%rd11];
	div.rn.f64 	%fd4, %fd3, %fd1;
	st.global.f64 	[%rd8], %fd4;

BB4_3:
	ret;
}

	// .globl	backwardError
.visible .entry backwardError(
	.param .u32 backwardError_param_0,
	.param .u64 backwardError_param_1,
	.param .u64 backwardError_param_2,
	.param .u64 backwardError_param_3
)
{
	.reg .pred 	%p<2>;
	.reg .b32 	%r<6>;
	.reg .f64 	%fd<6>;
	.reg .b64 	%rd<11>;


	ld.param.u32 	%r2, [backwardError_param_0];
	ld.param.u64 	%rd1, [backwardError_param_1];
	ld.param.u64 	%rd2, [backwardError_param_2];
	ld.param.u64 	%rd3, [backwardError_param_3];
	mov.u32 	%r3, %ctaid.x;
	mov.u32 	%r4, %ntid.x;
	mov.u32 	%r5, %tid.x;
	mad.lo.s32 	%r1, %r4, %r3, %r5;
	setp.ge.s32	%p1, %r1, %r2;
	@%p1 bra 	BB5_2;

	cvta.to.global.u64 	%rd4, %rd1;
	mul.wide.s32 	%rd5, %r1, 8;
	add.s64 	%rd6, %rd4, %rd5;
	cvta.to.global.u64 	%rd7, %rd2;
	add.s64 	%rd8, %rd7, %rd5;
	ld.global.f64 	%fd1, [%rd8];
	ld.global.f64 	%fd2, [%rd6];
	sub.f64 	%fd3, %fd2, %fd1;
	cvta.to.global.u64 	%rd9, %rd3;
	add.s64 	%rd10, %rd9, %rd5;
	ld.global.f64 	%fd4, [%rd10];
	add.f64 	%fd5, %fd4, %fd3;
	st.global.f64 	[%rd10], %fd5;

BB5_2:
	ret;
}

	// .globl	difference
.visible .entry difference(
	.param .u32 difference_param_0,
	.param .u64 difference_param_1,
	.param .u64 difference_param_2,
	.param .u64 difference_param_3
)
{
	.reg .pred 	%p<2>;
	.reg .b32 	%r<6>;
	.reg .f64 	%fd<4>;
	.reg .b64 	%rd<11>;


	ld.param.u32 	%r2, [difference_param_0];
	ld.param.u64 	%rd1, [difference_param_1];
	ld.param.u64 	%rd2, [difference_param_2];
	ld.param.u64 	%rd3, [difference_param_3];
	mov.u32 	%r3, %ctaid.x;
	mov.u32 	%r4, %ntid.x;
	mov.u32 	%r5, %tid.x;
	mad.lo.s32 	%r1, %r4, %r3, %r5;
	setp.ge.s32	%p1, %r1, %r2;
	@%p1 bra 	BB6_2;

	cvta.to.global.u64 	%rd4, %rd1;
	mul.wide.s32 	%rd5, %r1, 8;
	add.s64 	%rd6, %rd4, %rd5;
	cvta.to.global.u64 	%rd7, %rd2;
	add.s64 	%rd8, %rd7, %rd5;
	ld.global.f64 	%fd1, [%rd8];
	ld.global.f64 	%fd2, [%rd6];
	sub.f64 	%fd3, %fd2, %fd1;
	cvta.to.global.u64 	%rd9, %rd3;
	add.s64 	%rd10, %rd9, %rd5;
	st.global.f64 	[%rd10], %fd3;

BB6_2:
	ret;
}


