//
// Generated by NVIDIA NVVM Compiler
//
// Compiler Build ID: CL-21124049
// Cuda compilation tools, release 8.0, V8.0.44
// Based on LLVM 3.4svn
//

.version 5.0
.target sm_20
.address_size 64

	// .globl	reduce_exp
.extern .shared .align 8 .b8 sdata[];

.visible .entry reduce_exp(
	.param .u64 reduce_exp_param_0,
	.param .u64 reduce_exp_param_1,
	.param .u32 reduce_exp_param_2
)
{
	.reg .pred 	%p<18>;
	.reg .b32 	%r<31>;
	.reg .f64 	%fd<70>;
	.reg .b64 	%rd<15>;


	ld.param.u64 	%rd2, [reduce_exp_param_0];
	ld.param.u64 	%rd3, [reduce_exp_param_1];
	ld.param.u32 	%r5, [reduce_exp_param_2];
	mov.u32 	%r6, %tid.x;
	mov.u32 	%r7, %ctaid.x;
	shl.b32 	%r8, %r7, 1;
	mov.u32 	%r9, %ntid.x;
	mad.lo.s32 	%r30, %r8, %r9, %r6;
	mov.f64 	%fd67, 0d0000000000000000;
	mov.f64 	%fd68, %fd67;
	setp.ge.u32	%p1, %r30, %r5;
	@%p1 bra 	BB0_4;

BB0_1:
	mov.f64 	%fd1, %fd68;
	cvta.to.global.u64 	%rd4, %rd2;
	mul.wide.u32 	%rd5, %r30, 8;
	add.s64 	%rd6, %rd4, %rd5;
	ld.global.f64 	%fd27, [%rd6];
	add.f64 	%fd69, %fd1, %fd27;
	add.s32 	%r3, %r30, %r9;
	setp.ge.u32	%p2, %r3, %r5;
	@%p2 bra 	BB0_3;

	mul.wide.u32 	%rd8, %r3, 8;
	add.s64 	%rd9, %rd4, %rd8;
	ld.global.f64 	%fd28, [%rd9];
	add.f64 	%fd69, %fd69, %fd28;

BB0_3:
	mov.f64 	%fd68, %fd69;
	shl.b32 	%r12, %r9, 1;
	mov.u32 	%r13, %nctaid.x;
	mad.lo.s32 	%r30, %r12, %r13, %r30;
	setp.lt.u32	%p3, %r30, %r5;
	mov.f64 	%fd67, %fd68;
	@%p3 bra 	BB0_1;

BB0_4:
	mov.f64 	%fd65, %fd67;
	mul.wide.u32 	%rd10, %r6, 8;
	mov.u64 	%rd11, sdata;
	add.s64 	%rd1, %rd11, %rd10;
	st.shared.f64 	[%rd1], %fd65;
	bar.sync 	0;
	setp.lt.u32	%p4, %r9, 512;
	@%p4 bra 	BB0_8;

	setp.gt.u32	%p5, %r6, 255;
	mov.f64 	%fd66, %fd65;
	@%p5 bra 	BB0_7;

	ld.shared.f64 	%fd29, [%rd1+2048];
	add.f64 	%fd66, %fd65, %fd29;
	st.shared.f64 	[%rd1], %fd66;

BB0_7:
	mov.f64 	%fd65, %fd66;
	bar.sync 	0;

BB0_8:
	mov.f64 	%fd63, %fd65;
	setp.lt.u32	%p6, %r9, 256;
	@%p6 bra 	BB0_12;

	setp.gt.u32	%p7, %r6, 127;
	mov.f64 	%fd64, %fd63;
	@%p7 bra 	BB0_11;

	ld.shared.f64 	%fd30, [%rd1+1024];
	add.f64 	%fd64, %fd63, %fd30;
	st.shared.f64 	[%rd1], %fd64;

BB0_11:
	mov.f64 	%fd63, %fd64;
	bar.sync 	0;

BB0_12:
	mov.f64 	%fd61, %fd63;
	setp.lt.u32	%p8, %r9, 128;
	@%p8 bra 	BB0_16;

	setp.gt.u32	%p9, %r6, 63;
	mov.f64 	%fd62, %fd61;
	@%p9 bra 	BB0_15;

	ld.shared.f64 	%fd31, [%rd1+512];
	add.f64 	%fd62, %fd61, %fd31;
	st.shared.f64 	[%rd1], %fd62;

BB0_15:
	mov.f64 	%fd61, %fd62;
	bar.sync 	0;

BB0_16:
	mov.f64 	%fd60, %fd61;
	setp.gt.u32	%p10, %r6, 31;
	@%p10 bra 	BB0_29;

	setp.lt.u32	%p11, %r9, 64;
	@%p11 bra 	BB0_19;

	ld.volatile.shared.f64 	%fd32, [%rd1+256];
	add.f64 	%fd60, %fd60, %fd32;
	st.volatile.shared.f64 	[%rd1], %fd60;

BB0_19:
	mov.f64 	%fd59, %fd60;
	setp.lt.u32	%p12, %r9, 32;
	@%p12 bra 	BB0_21;

	ld.volatile.shared.f64 	%fd33, [%rd1+128];
	add.f64 	%fd59, %fd59, %fd33;
	st.volatile.shared.f64 	[%rd1], %fd59;

BB0_21:
	mov.f64 	%fd58, %fd59;
	setp.lt.u32	%p13, %r9, 16;
	@%p13 bra 	BB0_23;

	ld.volatile.shared.f64 	%fd34, [%rd1+64];
	add.f64 	%fd58, %fd58, %fd34;
	st.volatile.shared.f64 	[%rd1], %fd58;

BB0_23:
	mov.f64 	%fd57, %fd58;
	setp.lt.u32	%p14, %r9, 8;
	@%p14 bra 	BB0_25;

	ld.volatile.shared.f64 	%fd35, [%rd1+32];
	add.f64 	%fd57, %fd57, %fd35;
	st.volatile.shared.f64 	[%rd1], %fd57;

BB0_25:
	mov.f64 	%fd56, %fd57;
	setp.lt.u32	%p15, %r9, 4;
	@%p15 bra 	BB0_27;

	ld.volatile.shared.f64 	%fd36, [%rd1+16];
	add.f64 	%fd56, %fd56, %fd36;
	st.volatile.shared.f64 	[%rd1], %fd56;

BB0_27:
	setp.lt.u32	%p16, %r9, 2;
	@%p16 bra 	BB0_29;

	ld.volatile.shared.f64 	%fd37, [%rd1+8];
	add.f64 	%fd38, %fd56, %fd37;
	st.volatile.shared.f64 	[%rd1], %fd38;

BB0_29:
	setp.ne.s32	%p17, %r6, 0;
	@%p17 bra 	BB0_31;

	ld.shared.f64 	%fd39, [sdata];
	cvta.to.global.u64 	%rd12, %rd3;
	mul.wide.u32 	%rd13, %r7, 8;
	add.s64 	%rd14, %rd12, %rd13;
	st.global.f64 	[%rd14], %fd39;

BB0_31:
	ret;
}


